name: Manual Operations

on:
  workflow_dispatch:
    inputs:
      operation:
        description: 'Operation to perform'
        required: true
        type: choice
        options:
        - health-check
        - restart-services
        - update-monitoring
        - cluster-status
        - backup-config
        - roll-back
      target_hosts:
        description: 'Target hosts'
        required: false
        default: 'all'
        type: choice
        options:
        - all
        - k8s
        - k8s_controller
        - k8s_worker
        - proxmox
      service_name:
        description: 'Service name (for restart-services)'
        required: false
        default: ''
      dry_run:
        description: 'Dry run only'
        required: false
        default: true
        type: boolean

jobs:
  manual-operation:
    name: Execute Manual Operation
    runs-on: self-hosted  # Uses existing homelab runner infrastructure
    environment: production
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python & Ansible
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        pip install ansible-core kubernetes PyYAML
        
    - name: Set up SSH key
      uses: webfactory/ssh-agent@v0.8.0
      with:
        ssh-private-key: ${{ secrets.ANSIBLE_SSH_PRIVATE_KEY }}
        
    - name: Configure Ansible vault
      run: |
        echo "${{ secrets.ANSIBLE_VAULT_PASSWORD }}" > .vault_password
        chmod 600 .vault_password
        
    - name: Execute Health Check
      if: github.event.inputs.operation == 'health-check'
      run: |
        echo "ðŸ¥ Running health check on ${{ github.event.inputs.target_hosts }}..."
        
        # Run the health check script if it exists
        if [ -f "k8s-health-monitoring/scripts/health-check.sh" ]; then
          ansible ${{ github.event.inputs.target_hosts }} -i inventories/production/hosts.ini \
            -m script -a "k8s-health-monitoring/scripts/health-check.sh" \
            --vault-password-file=.vault_password
        else
          # Basic health checks
          ansible ${{ github.event.inputs.target_hosts }} -i inventories/production/hosts.ini \
            -m shell -a "uptime && df -h && free -m" \
            --vault-password-file=.vault_password
        fi
        
    - name: Restart Services
      if: github.event.inputs.operation == 'restart-services'
      run: |
        echo "ðŸ”„ Restarting services on ${{ github.event.inputs.target_hosts }}..."
        
        if [ -z "${{ github.event.inputs.service_name }}" ]; then
          echo "âŒ Service name required for restart operation"
          exit 1
        fi
        
        if [ "${{ github.event.inputs.dry_run }}" = "true" ]; then
          echo "ðŸ§ª DRY RUN: Would restart ${{ github.event.inputs.service_name }}"
          ansible ${{ github.event.inputs.target_hosts }} -i inventories/production/hosts.ini \
            -m shell -a "systemctl status ${{ github.event.inputs.service_name }}" \
            --vault-password-file=.vault_password
        else
          ansible ${{ github.event.inputs.target_hosts }} -i inventories/production/hosts.ini \
            -m systemd -a "name=${{ github.event.inputs.service_name }} state=restarted" \
            --vault-password-file=.vault_password --become
        fi
        
    - name: Update Monitoring
      if: github.event.inputs.operation == 'update-monitoring'
      run: |
        echo "ðŸ“Š Updating monitoring stack..."
        
        if [ "${{ github.event.inputs.dry_run }}" = "true" ]; then
          ansible-playbook k8s-health-monitoring/playbooks/deploy-monitoring.yml \
            -i inventories/production/hosts.ini \
            --limit ${{ github.event.inputs.target_hosts }} \
            --vault-password-file=.vault_password \
            --check --diff
        else
          ansible-playbook k8s-health-monitoring/playbooks/deploy-monitoring.yml \
            -i inventories/production/hosts.ini \
            --limit ${{ github.event.inputs.target_hosts }} \
            --vault-password-file=.vault_password \
            --diff
        fi
        
    - name: Cluster Status
      if: github.event.inputs.operation == 'cluster-status'
      run: |
        echo "ðŸ” Checking cluster status..."
        
        # K8s API health
        echo "=== Kubernetes API Health ==="
        ansible k8s_controller[0] -i inventories/production/hosts.ini \
          -m shell -a "curl -s -k https://192.168.1.99:6443/healthz" \
          --vault-password-file=.vault_password
          
        # Node status
        echo "=== Node Status ==="
        ansible k8s_controller[0] -i inventories/production/hosts.ini \
          -m shell -a "kubectl get nodes -o wide" \
          --vault-password-file=.vault_password || true
          
        # Pod status
        echo "=== Pod Status ==="
        ansible k8s_controller[0] -i inventories/production/hosts.ini \
          -m shell -a "kubectl get pods --all-namespaces | grep -E '(Error|CrashLoop|Pending)' || echo 'All pods healthy'" \
          --vault-password-file=.vault_password || true
          
        # Service status on nodes
        echo "=== Service Status ==="
        ansible k8s -i inventories/production/hosts.ini \
          -m shell -a "systemctl status kubelet containerd --no-pager -l" \
          --vault-password-file=.vault_password || true
          
    - name: Backup Config
      if: github.event.inputs.operation == 'backup-config'
      run: |
        echo "ðŸ’¾ Backing up configurations..."
        
        # Create backup directory with timestamp
        BACKUP_DIR="backups/$(date +%Y%m%d-%H%M%S)"
        mkdir -p "$BACKUP_DIR"
        
        # Backup K8s configs from controller
        ansible k8s_controller[0] -i inventories/production/hosts.ini \
          -m fetch -a "src=/etc/kubernetes/admin.conf dest=$BACKUP_DIR/kubeconfig flat=yes" \
          --vault-password-file=.vault_password || true
          
        # Backup important configs
        ansible k8s -i inventories/production/hosts.ini \
          -m fetch -a "src=/etc/systemd/system/kubelet.service.d/10-kubeadm.conf dest=$BACKUP_DIR/ flat=no" \
          --vault-password-file=.vault_password || true
          
        echo "âœ… Backup completed in $BACKUP_DIR"
        
    - name: Roll Back
      if: github.event.inputs.operation == 'roll-back'
      run: |
        echo "âª Rolling back last deployment..."
        
        if [ "${{ github.event.inputs.dry_run }}" = "true" ]; then
          echo "ðŸ§ª DRY RUN: Would roll back monitoring deployment"
          echo "This would:"
          echo "  - Remove kube-state-metrics from cluster"
          echo "  - Stop and disable cAdvisor services"
          echo "  - Restore previous configurations"
        else
          echo "âš ï¸  LIVE ROLLBACK - This will revert monitoring changes"
          
          # Remove kube-state-metrics
          ansible k8s_controller[0] -i inventories/production/hosts.ini \
            -m shell -a "kubectl delete -f k8s-health-monitoring/monitoring/kube-state-metrics.yaml" \
            --vault-password-file=.vault_password || true
            
          # Stop cAdvisor
          ansible k8s -i inventories/production/hosts.ini \
            -m systemd -a "name=cadvisor state=stopped enabled=no" \
            --vault-password-file=.vault_password --become || true
            
          echo "âœ… Rollback completed"
        fi
        
    - name: Clean up
      if: always()
      run: |
        rm -f .vault_password
        
    - name: Create operation summary
      if: always()
      run: |
        echo "## ðŸ› ï¸ Manual Operation Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Operation:** ${{ github.event.inputs.operation }}" >> $GITHUB_STEP_SUMMARY
        echo "**Target Hosts:** ${{ github.event.inputs.target_hosts }}" >> $GITHUB_STEP_SUMMARY
        echo "**Dry Run:** ${{ github.event.inputs.dry_run }}" >> $GITHUB_STEP_SUMMARY
        echo "**Status:** ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ "${{ job.status }}" = "success" ]; then
          echo "âœ… Operation completed successfully!" >> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ Operation failed. Check logs for details." >> $GITHUB_STEP_SUMMARY
        fi